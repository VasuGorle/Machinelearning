import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import tensorflow as tf
dataset = pd.read_csv('Example.csv')
X = dataset.iloc[:, :-1].values
y = dataset.iloc[:, -1].values
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)
from sklearn.linear_model import Ridge
R=Ridge(alpha=2)
R.fit( X_train, y_train )
from sklearn.linear_model import Lasso
L=Lasso(alpha=20)
L.fit(X_train, y_train)
from sklearn.linear_model import BayesianRidge
B=BayesianRidge()
m=tf.keras.models.Sequential()
m.add(tf.keras.layers.Dense(1,input_shape=(8,)))
from sklearn.linear_model import ElasticNet
E=ElasticNet(random_state=0)
from sklearn.cross_decomposition import PLSRegression
P = PLSRegression(n_components=7)
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.ensemble import RandomForestRegressor
regressor = RandomForestRegressor(n_estimators = 50, random_state = 0)
regressor.fit(X_train, y_train)
L.fit(X_train, y_train)
B.fit(X_train, y_train)
E.fit(X_train, y_train)
P.fit(X_train, y_train)
y_pred=regressor.predict(X_test)
 y_pred1=R.predict(X_test)
 y_pred2=L.predict(X_test)
 y_pred3=B.predict(X_test)
 y_pred4=E.predict(X_test)
 y_pred5=P.predict(X_test)
 print(R.predict([[1,4,1280,6,1,5000,5,32]]))
 print(regressor.predict([[1,1,778,6,1,5000,5,32]]))
 print(E.predict([[1,1,778,6,1,5000,5,32]]))
from sklearn.metrics import mean_absolute_error as mae
from sklearn.metrics import mean_squared_error as mse
print(mae(y_pred4,y_test))
print(mae(y_pred5,y_test))
print(mae(y_pred1,y_test))
print(mae(y_pred2,y_test))
print(mae(y_pred,y_test))
print(mae(y_pred3,y_test))



# Create polynomial features
poly_features = PolynomialFeatures(degree=8)  # Set the degree of the polynomial
X_poly = poly_features.fit_transform(X_train)

# Train the polynomial regression model
poly_regression = LinearRegression()
poly_regression.fit(X_poly, y_train
